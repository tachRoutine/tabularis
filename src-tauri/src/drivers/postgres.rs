use crate::drivers::common::extract_postgres_value;
use crate::models::{
    ConnectionParams, ForeignKey, Index, Pagination, QueryResult, RoutineInfo, RoutineParameter,
    TableColumn, TableInfo, ViewInfo,
};
use crate::pool_manager::get_postgres_pool;
use sqlx::{Column, Row};

// Helper function to escape double quotes in identifiers for PostgreSQL
fn escape_identifier(name: &str) -> String {
    name.replace('"', "\"\"")
}

pub async fn get_databases(params: &ConnectionParams) -> Result<Vec<String>, String> {
    let pool = get_postgres_pool(params).await?;
    let rows = sqlx::query(
        "SELECT datname::text FROM pg_database WHERE datistemplate = false ORDER BY datname",
    )
    .fetch_all(&pool)
    .await
    .map_err(|e| e.to_string())?;
    Ok(rows
        .iter()
        .map(|r| r.try_get("datname").unwrap_or_default())
        .collect())
}

pub async fn get_tables(params: &ConnectionParams) -> Result<Vec<TableInfo>, String> {
    log::debug!(
        "PostgreSQL: Fetching tables for database: {}",
        params.database
    );
    let pool = get_postgres_pool(params).await?;
    let rows = sqlx::query(
        "SELECT table_name as name FROM information_schema.tables WHERE table_schema = 'public' ORDER BY table_name ASC",
    )
    .fetch_all(&pool)
    .await
    .map_err(|e| e.to_string())?;
    let tables: Vec<TableInfo> = rows
        .iter()
        .map(|r| TableInfo {
            name: r.try_get("name").unwrap_or_default(),
        })
        .collect();
    log::debug!(
        "PostgreSQL: Found {} tables in {}",
        tables.len(),
        params.database
    );
    Ok(tables)
}

pub async fn get_columns(
    params: &ConnectionParams,
    table_name: &str,
) -> Result<Vec<TableColumn>, String> {
    let pool = get_postgres_pool(params).await?;

    // Postgres auto increment is usually sequences (nextval) or GENERATED BY DEFAULT/ALWAYS AS IDENTITY
    let query = r#"
        SELECT
            c.column_name,
            c.data_type,
            c.is_nullable,
            c.column_default,
            c.is_identity,
            (SELECT COUNT(*) FROM information_schema.table_constraints tc
             JOIN information_schema.key_column_usage kcu ON tc.constraint_name = kcu.constraint_name
             WHERE tc.constraint_type = 'PRIMARY KEY'
             AND kcu.table_name = c.table_name
             AND kcu.column_name = c.column_name) > 0 as is_pk
        FROM information_schema.columns c
        WHERE c.table_schema = 'public' AND c.table_name = $1
        ORDER BY c.ordinal_position
    "#;

    let rows = sqlx::query(query)
        .bind(table_name)
        .fetch_all(&pool)
        .await
        .map_err(|e| e.to_string())?;

    Ok(rows
        .iter()
        .map(|r| {
            let null_str: String = r.try_get("is_nullable").unwrap_or_default();
            let is_pk: i64 = r.try_get("is_pk").unwrap_or(0);
            let default_val: String = r.try_get("column_default").unwrap_or_default();
            let is_identity: String = r.try_get("is_identity").unwrap_or_default(); // YES/NO

            let is_auto = is_identity == "YES" || default_val.contains("nextval");

            TableColumn {
                name: r.try_get("column_name").unwrap_or_default(),
                data_type: r.try_get("data_type").unwrap_or_default(),
                is_pk: is_pk > 0,
                is_nullable: null_str == "YES",
                is_auto_increment: is_auto,
            }
        })
        .collect())
}

pub async fn get_foreign_keys(
    params: &ConnectionParams,
    table_name: &str,
) -> Result<Vec<ForeignKey>, String> {
    let pool = get_postgres_pool(params).await?;

    let query = r#"
        SELECT
            tc.constraint_name,
            kcu.column_name,
            ccu.table_name AS foreign_table_name,
            ccu.column_name AS foreign_column_name,
            rc.update_rule,
            rc.delete_rule
        FROM
            information_schema.table_constraints AS tc
            JOIN information_schema.key_column_usage AS kcu
            ON tc.constraint_name = kcu.constraint_name
            AND tc.table_schema = kcu.table_schema
            JOIN information_schema.constraint_column_usage AS ccu
            ON ccu.constraint_name = tc.constraint_name
            AND ccu.table_schema = tc.table_schema
            JOIN information_schema.referential_constraints AS rc
            ON rc.constraint_name = tc.constraint_name
        WHERE tc.constraint_type = 'FOREIGN KEY'
        AND tc.table_name = $1
    "#;

    let rows = sqlx::query(query)
        .bind(table_name)
        .fetch_all(&pool)
        .await
        .map_err(|e| e.to_string())?;

    Ok(rows
        .iter()
        .map(|r| ForeignKey {
            name: r.try_get("constraint_name").unwrap_or_default(),
            column_name: r.try_get("column_name").unwrap_or_default(),
            ref_table: r.try_get("foreign_table_name").unwrap_or_default(),
            ref_column: r.try_get("foreign_column_name").unwrap_or_default(),
            on_update: r.try_get("update_rule").ok(),
            on_delete: r.try_get("delete_rule").ok(),
        })
        .collect())
}

// Batch function: Get all columns for all tables in one query
pub async fn get_all_columns_batch(
    params: &ConnectionParams,
) -> Result<std::collections::HashMap<String, Vec<TableColumn>>, String> {
    use std::collections::HashMap;
    let pool = get_postgres_pool(params).await?;

    let query = r#"
        SELECT
            c.table_name,
            c.column_name,
            c.data_type,
            c.is_nullable,
            c.column_default,
            c.is_identity,
            (SELECT COUNT(*) FROM information_schema.table_constraints tc
             JOIN information_schema.key_column_usage kcu ON tc.constraint_name = kcu.constraint_name
             WHERE tc.constraint_type = 'PRIMARY KEY'
             AND kcu.table_name = c.table_name
             AND kcu.column_name = c.column_name) > 0 as is_pk
        FROM information_schema.columns c
        WHERE c.table_schema = 'public'
        ORDER BY c.table_name, c.ordinal_position
    "#;

    let rows = sqlx::query(query)
        .fetch_all(&pool)
        .await
        .map_err(|e| e.to_string())?;

    let mut result: HashMap<String, Vec<TableColumn>> = HashMap::new();

    for row in rows {
        let table_name: String = row.try_get("table_name").unwrap_or_default();
        let null_str: String = row.try_get("is_nullable").unwrap_or_default();
        let is_pk: i64 = row.try_get("is_pk").unwrap_or(0);
        let default_val: String = row.try_get("column_default").unwrap_or_default();
        let is_identity: String = row.try_get("is_identity").unwrap_or_default();

        let is_auto = is_identity == "YES" || default_val.contains("nextval");

        let column = TableColumn {
            name: row.try_get("column_name").unwrap_or_default(),
            data_type: row.try_get("data_type").unwrap_or_default(),
            is_pk: is_pk > 0,
            is_nullable: null_str == "YES",
            is_auto_increment: is_auto,
        };

        result
            .entry(table_name)
            .or_insert_with(Vec::new)
            .push(column);
    }

    Ok(result)
}

// Batch function: Get all foreign keys for all tables in one query
pub async fn get_all_foreign_keys_batch(
    params: &ConnectionParams,
) -> Result<std::collections::HashMap<String, Vec<ForeignKey>>, String> {
    use std::collections::HashMap;
    let pool = get_postgres_pool(params).await?;

    let query = r#"
        SELECT
            tc.table_name,
            tc.constraint_name,
            kcu.column_name,
            ccu.table_name AS foreign_table_name,
            ccu.column_name AS foreign_column_name,
            rc.update_rule,
            rc.delete_rule
        FROM
            information_schema.table_constraints AS tc
            JOIN information_schema.key_column_usage AS kcu
            ON tc.constraint_name = kcu.constraint_name
            AND tc.table_schema = kcu.table_schema
            JOIN information_schema.constraint_column_usage AS ccu
            ON ccu.constraint_name = tc.constraint_name
            AND ccu.table_schema = tc.table_schema
            JOIN information_schema.referential_constraints AS rc
            ON rc.constraint_name = tc.constraint_name
        WHERE tc.constraint_type = 'FOREIGN KEY'
        AND tc.table_schema = 'public'
    "#;

    let rows = sqlx::query(query)
        .fetch_all(&pool)
        .await
        .map_err(|e| e.to_string())?;

    let mut result: HashMap<String, Vec<ForeignKey>> = HashMap::new();

    for row in rows {
        let table_name: String = row.try_get("table_name").unwrap_or_default();

        let fk = ForeignKey {
            name: row.try_get("constraint_name").unwrap_or_default(),
            column_name: row.try_get("column_name").unwrap_or_default(),
            ref_table: row.try_get("foreign_table_name").unwrap_or_default(),
            ref_column: row.try_get("foreign_column_name").unwrap_or_default(),
            on_update: row.try_get("update_rule").ok(),
            on_delete: row.try_get("delete_rule").ok(),
        };

        result.entry(table_name).or_insert_with(Vec::new).push(fk);
    }

    Ok(result)
}

pub async fn get_indexes(
    params: &ConnectionParams,
    table_name: &str,
) -> Result<Vec<Index>, String> {
    let pool = get_postgres_pool(params).await?;

    let query = r#"
        SELECT
            i.relname as index_name,
            a.attname as column_name,
            ix.indisunique as is_unique,
            ix.indisprimary as is_primary,
            array_position(ix.indkey, a.attnum) as seq_in_index
        FROM
            pg_class t,
            pg_class i,
            pg_index ix,
            pg_attribute a
        WHERE
            t.oid = ix.indrelid
            AND i.oid = ix.indexrelid
            AND a.attrelid = t.oid
            AND a.attnum = ANY(ix.indkey)
            AND t.relkind = 'r'
            AND t.relname = $1
        ORDER BY
            t.relname,
            i.relname,
            seq_in_index
    "#;

    let rows = sqlx::query(query)
        .bind(table_name)
        .fetch_all(&pool)
        .await
        .map_err(|e| e.to_string())?;

    Ok(rows
        .iter()
        .map(|r| Index {
            name: r.try_get("index_name").unwrap_or_default(),
            column_name: r.try_get("column_name").unwrap_or_default(),
            is_unique: r.try_get("is_unique").unwrap_or(false),
            is_primary: r.try_get("is_primary").unwrap_or(false),
            seq_in_index: r.try_get::<i32, _>("seq_in_index").unwrap_or(0),
        })
        .collect())
}

pub async fn delete_record(
    params: &ConnectionParams,
    table: &str,
    pk_col: &str,
    pk_val: serde_json::Value,
) -> Result<u64, String> {
    let pool = get_postgres_pool(params).await?;

    let query = format!("DELETE FROM \"{}\" WHERE \"{}\" = $1", table, pk_col);

    let result = match pk_val {
        serde_json::Value::Number(n) => {
            if n.is_i64() {
                sqlx::query(&query).bind(n.as_i64()).execute(&pool).await
            } else {
                sqlx::query(&query).bind(n.as_f64()).execute(&pool).await
            }
        }
        serde_json::Value::String(s) => sqlx::query(&query).bind(s).execute(&pool).await,
        _ => return Err("Unsupported PK type".into()),
    };

    result.map(|r| r.rows_affected()).map_err(|e| e.to_string())
}

pub async fn update_record(
    params: &ConnectionParams,
    table: &str,
    pk_col: &str,
    pk_val: serde_json::Value,
    col_name: &str,
    new_val: serde_json::Value,
) -> Result<u64, String> {
    let pool = get_postgres_pool(params).await?;

    let mut qb = sqlx::QueryBuilder::new(format!("UPDATE \"{}\" SET \"{}\" = ", table, col_name));

    match new_val {
        serde_json::Value::Number(n) => {
            if n.is_i64() {
                qb.push_bind(n.as_i64());
            } else {
                qb.push_bind(n.as_f64());
            }
        }
        serde_json::Value::String(s) => {
            qb.push_bind(s);
        }
        serde_json::Value::Bool(b) => {
            qb.push_bind(b);
        }
        serde_json::Value::Null => {
            qb.push("NULL");
        }
        _ => return Err("Unsupported Value type".into()),
    }

    qb.push(format!(" WHERE \"{}\" = ", pk_col));

    match pk_val {
        serde_json::Value::Number(n) => {
            if n.is_i64() {
                qb.push_bind(n.as_i64());
            } else {
                qb.push_bind(n.as_f64());
            }
        }
        serde_json::Value::String(s) => {
            qb.push_bind(s);
        }
        _ => return Err("Unsupported PK type".into()),
    }

    let query = qb.build();
    let result = query.execute(&pool).await.map_err(|e| e.to_string())?;
    Ok(result.rows_affected())
}

pub async fn insert_record(
    params: &ConnectionParams,
    table: &str,
    data: std::collections::HashMap<String, serde_json::Value>,
) -> Result<u64, String> {
    let pool = get_postgres_pool(params).await?;

    let mut cols = Vec::new();
    let mut vals = Vec::new();

    for (k, v) in data {
        cols.push(format!("\"{}\"", k));
        vals.push(v);
    }

    if cols.is_empty() {
        return Err("No data to insert".into());
    }

    let mut qb = sqlx::QueryBuilder::new(format!(
        "INSERT INTO \"{}\" ({}) VALUES (",
        table,
        cols.join(", ")
    ));

    let mut separated = qb.separated(", ");
    for val in vals {
        match val {
            serde_json::Value::Number(n) => {
                if n.is_i64() {
                    separated.push_bind(n.as_i64());
                } else {
                    separated.push_bind(n.as_f64());
                }
            }
            serde_json::Value::String(s) => {
                separated.push_bind(s);
            }
            serde_json::Value::Bool(b) => {
                separated.push_bind(b);
            }
            serde_json::Value::Null => {
                separated.push("NULL");
            }
            _ => return Err("Unsupported value type".into()),
        }
    }
    separated.push_unseparated(")");

    let query = qb.build();
    let result = query.execute(&pool).await.map_err(|e| e.to_string())?;
    Ok(result.rows_affected())
}

/// Extracts ORDER BY clause from a SQL query (case-insensitive)
fn extract_order_by(query: &str) -> String {
    let query_upper = query.to_uppercase();
    if let Some(pos) = query_upper.rfind("ORDER BY") {
        query[pos..].trim().to_string()
    } else {
        String::new()
    }
}

/// Removes ORDER BY clause from a SQL query
fn remove_order_by(query: &str) -> String {
    let query_upper = query.to_uppercase();
    if let Some(pos) = query_upper.rfind("ORDER BY") {
        query[..pos].trim().to_string()
    } else {
        query.to_string()
    }
}

pub async fn get_table_ddl(params: &ConnectionParams, table_name: &str) -> Result<String, String> {
    let cols = get_columns(params, table_name).await?;
    if cols.is_empty() {
        return Err(format!("Table {} not found or empty", table_name));
    }

    let mut defs = Vec::new();
    let mut pks = Vec::new();

    for col in cols {
        let mut def = format!("\"{}\" {}", col.name, col.data_type);

        if !col.is_nullable {
            def.push_str(" NOT NULL");
        }

        if col.is_pk {
            pks.push(format!("\"{}\"", col.name));
        }
        defs.push(def);
    }

    if !pks.is_empty() {
        defs.push(format!("PRIMARY KEY ({})", pks.join(", ")));
    }

    Ok(format!(
        "CREATE TABLE public.\"{}\" (\n  {}\n);",
        table_name,
        defs.join(",\n  ")
    ))
}

pub async fn execute_query(
    params: &ConnectionParams,
    query: &str,
    limit: Option<u32>,
    page: u32,
) -> Result<QueryResult, String> {
    let pool = get_postgres_pool(params).await?;
    let mut conn = pool.acquire().await.map_err(|e| e.to_string())?;

    let is_select = query.trim_start().to_uppercase().starts_with("SELECT");
    let mut pagination: Option<Pagination> = None;
    let final_query: String;
    let mut manual_limit = limit;
    let mut truncated = false;

    if is_select && limit.is_some() {
        let l = limit.unwrap();
        let offset = (page - 1) * l;

        let count_q = format!("SELECT COUNT(*) FROM ({}) as count_wrapper", query);
        let count_res = sqlx::query(&count_q).fetch_one(&mut *conn).await;

        let total_rows: u64 = if let Ok(row) = count_res {
            row.try_get::<i64, _>(0).unwrap_or(0) as u64
        } else {
            0
        };

        pagination = Some(Pagination {
            page,
            page_size: l,
            total_rows,
        });

        // Set truncated if there are more results than shown
        truncated = total_rows > l as u64;

        // Extract ORDER BY clause from the original query to preserve sorting
        let order_by_clause = extract_order_by(query);

        if !order_by_clause.is_empty() {
            // Remove ORDER BY from inner query and add it to outer query
            let query_without_order = remove_order_by(query);
            final_query = format!(
                "SELECT * FROM ({}) as data_wrapper {} LIMIT {} OFFSET {}",
                query_without_order, order_by_clause, l, offset
            );
        } else {
            final_query = format!(
                "SELECT * FROM ({}) as data_wrapper LIMIT {} OFFSET {}",
                query, l, offset
            );
        }

        manual_limit = None;
    } else {
        final_query = query.to_string();
    }

    // Streaming
    let mut rows_stream = sqlx::query(&final_query).fetch(&mut *conn);

    let mut columns: Vec<String> = Vec::new();
    let mut json_rows = Vec::new();

    use futures::stream::StreamExt;

    while let Some(result) = rows_stream.next().await {
        match result {
            Ok(row) => {
                if columns.is_empty() {
                    columns = row.columns().iter().map(|c| c.name().to_string()).collect();
                }

                if let Some(l) = manual_limit {
                    if json_rows.len() >= l as usize {
                        truncated = true;
                        break;
                    }
                }

                let mut json_row = Vec::new();
                for (i, _) in row.columns().iter().enumerate() {
                    let val = extract_postgres_value(&row, i);
                    json_row.push(val);
                }
                json_rows.push(json_row);
            }
            Err(e) => return Err(e.to_string()),
        }
    }

    Ok(QueryResult {
        columns,
        rows: json_rows,
        affected_rows: 0,
        truncated,
        pagination,
    })
}

pub async fn get_views(params: &ConnectionParams) -> Result<Vec<ViewInfo>, String> {
    log::debug!(
        "PostgreSQL: Fetching views for database: {}",
        params.database
    );
    let pool = get_postgres_pool(params).await?;
    let rows = sqlx::query(
        "SELECT viewname as name FROM pg_views WHERE schemaname = 'public' ORDER BY viewname ASC",
    )
    .fetch_all(&pool)
    .await
    .map_err(|e| e.to_string())?;
    let views: Vec<ViewInfo> = rows
        .iter()
        .map(|r| ViewInfo {
            name: r.try_get("name").unwrap_or_default(),
            definition: None,
        })
        .collect();
    log::debug!(
        "PostgreSQL: Found {} views in {}",
        views.len(),
        params.database
    );
    Ok(views)
}

pub async fn get_view_definition(
    params: &ConnectionParams,
    view_name: &str,
) -> Result<String, String> {
    let pool = get_postgres_pool(params).await?;
    let query = "SELECT pg_get_viewdef($1, true) as definition";
    let row = sqlx::query(query)
        .bind(view_name)
        .fetch_one(&pool)
        .await
        .map_err(|e| format!("Failed to get view definition: {}", e))?;

    let definition: String = row.try_get("definition").unwrap_or_default();
    Ok(format!(
        "CREATE OR REPLACE VIEW {} AS\n{}",
        view_name, definition
    ))
}

pub async fn create_view(
    params: &ConnectionParams,
    view_name: &str,
    definition: &str,
) -> Result<(), String> {
    let pool = get_postgres_pool(params).await?;
    let escaped_name = escape_identifier(view_name);
    let query = format!("CREATE VIEW \"{}\" AS {}", escaped_name, definition);
    sqlx::query(&query)
        .execute(&pool)
        .await
        .map_err(|e| format!("Failed to create view: {}", e))?;
    Ok(())
}

pub async fn alter_view(
    params: &ConnectionParams,
    view_name: &str,
    definition: &str,
) -> Result<(), String> {
    let pool = get_postgres_pool(params).await?;
    let escaped_name = escape_identifier(view_name);
    let query = format!(
        "CREATE OR REPLACE VIEW \"{}\" AS {}",
        escaped_name, definition
    );
    sqlx::query(&query)
        .execute(&pool)
        .await
        .map_err(|e| format!("Failed to alter view: {}", e))?;
    Ok(())
}

pub async fn drop_view(params: &ConnectionParams, view_name: &str) -> Result<(), String> {
    let pool = get_postgres_pool(params).await?;
    let escaped_name = escape_identifier(view_name);
    let query = format!("DROP VIEW IF EXISTS \"{}\"", escaped_name);
    sqlx::query(&query)
        .execute(&pool)
        .await
        .map_err(|e| format!("Failed to drop view: {}", e))?;
    Ok(())
}

pub async fn get_view_columns(
    params: &ConnectionParams,
    view_name: &str,
) -> Result<Vec<TableColumn>, String> {
    let pool = get_postgres_pool(params).await?;

    let query = r#"
        SELECT
            c.column_name,
            c.data_type,
            c.is_nullable,
            c.column_default,
            c.is_identity,
            (SELECT COUNT(*) FROM information_schema.table_constraints tc
             JOIN information_schema.key_column_usage kcu ON tc.constraint_name = kcu.constraint_name
             WHERE tc.constraint_type = 'PRIMARY KEY'
             AND kcu.table_name = c.table_name
             AND kcu.column_name = c.column_name) > 0 as is_pk
        FROM information_schema.columns c
        WHERE c.table_schema = 'public' AND c.table_name = $1
        ORDER BY c.ordinal_position
    "#;

    let rows = sqlx::query(query)
        .bind(view_name)
        .fetch_all(&pool)
        .await
        .map_err(|e| e.to_string())?;

    Ok(rows
        .iter()
        .map(|r| {
            let null_str: String = r.try_get("is_nullable").unwrap_or_default();
            let is_pk: i64 = r.try_get("is_pk").unwrap_or(0);
            let default_val: String = r.try_get("column_default").unwrap_or_default();
            let is_identity: String = r.try_get("is_identity").unwrap_or_default();

            let is_auto = is_identity == "YES" || default_val.contains("nextval");

            TableColumn {
                name: r.try_get("column_name").unwrap_or_default(),
                data_type: r.try_get("data_type").unwrap_or_default(),
                is_pk: is_pk > 0,
                is_nullable: null_str == "YES",
                is_auto_increment: is_auto,
            }
        })
        .collect())
}

pub async fn get_routines(params: &ConnectionParams) -> Result<Vec<RoutineInfo>, String> {
    let pool = get_postgres_pool(params).await?;
    let query = r#"
            SELECT proname, prokind
            FROM pg_proc
            WHERE pronamespace = (SELECT oid FROM pg_namespace WHERE nspname = 'public')
            AND prokind IN ('f', 'p')
            ORDER BY proname
        "#;

    let rows = sqlx::query(query)
        .fetch_all(&pool)
        .await
        .map_err(|e| e.to_string())?;

    Ok(rows
        .iter()
        .map(|r| {
            let prokind: i8 = r.try_get("prokind").unwrap_or(b'f' as i8); // f=function, p=procedure
            let routine_type = match prokind as u8 as char {
                'p' => "PROCEDURE",
                _ => "FUNCTION",
            };

            RoutineInfo {
                name: r.try_get("proname").unwrap_or_default(),
                routine_type: routine_type.to_string(),
                definition: None,
            }
        })
        .collect())
}

pub async fn get_routine_parameters(
    params: &ConnectionParams,
    routine_name: &str,
) -> Result<Vec<RoutineParameter>, String> {
    let pool = get_postgres_pool(params).await?;

    // 1. Get return type for functions
    let return_type_query = r#"
            SELECT data_type, routine_type
            FROM information_schema.routines
            WHERE routine_schema = 'public' AND routine_name = $1
            LIMIT 1
        "#;

    let routine_info = sqlx::query(return_type_query)
        .bind(routine_name)
        .fetch_optional(&pool)
        .await
        .map_err(|e| e.to_string())?;

    let mut parameters = Vec::new();

    if let Some(info) = routine_info {
        let routine_type: String = info.try_get("routine_type").unwrap_or_default();
        if routine_type == "FUNCTION" {
            let data_type: String = info.try_get("data_type").unwrap_or_default();
            // Exclude void or trigger returns if not relevant
            if !data_type.eq_ignore_ascii_case("void") && !data_type.eq_ignore_ascii_case("trigger")
            {
                parameters.push(RoutineParameter {
                    name: "".to_string(), // Empty name for return value
                    data_type,
                    mode: "OUT".to_string(),
                    ordinal_position: 0,
                });
            }
        }
    }

    // 2. Get parameters
    let query = r#"
            SELECT p.parameter_name, p.data_type, p.parameter_mode, p.ordinal_position
            FROM information_schema.parameters p
            JOIN information_schema.routines r ON p.specific_name = r.specific_name
            WHERE r.routine_schema = 'public' AND r.routine_name = $1
            ORDER BY p.ordinal_position
        "#;

    let rows = sqlx::query(query)
        .bind(routine_name)
        .fetch_all(&pool)
        .await
        .map_err(|e| e.to_string())?;

    parameters.extend(rows.iter().map(|r| RoutineParameter {
        name: r.try_get("parameter_name").unwrap_or_default(),
        data_type: r.try_get("data_type").unwrap_or_default(),
        mode: r.try_get("parameter_mode").unwrap_or_default(),
        ordinal_position: r.try_get("ordinal_position").unwrap_or(0),
    }));

    Ok(parameters)
}

pub async fn get_routine_definition(
    params: &ConnectionParams,
    routine_name: &str,
    _routine_type: &str,
) -> Result<String, String> {
    let pool = get_postgres_pool(params).await?;

    let query = r#"
            SELECT pg_get_functiondef(p.oid) as definition
            FROM pg_proc p
            JOIN pg_namespace n ON p.pronamespace = n.oid
            WHERE n.nspname = 'public' AND p.proname = $1
            LIMIT 1
        "#;

    let row = sqlx::query(query)
        .bind(routine_name)
        .fetch_one(&pool)
        .await
        .map_err(|e| e.to_string())?;

    let definition: String = row.try_get("definition").unwrap_or_default();
    Ok(definition)
}
