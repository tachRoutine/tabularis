use sqlx::postgres::PgRow;
use sqlx::{Column, Connection, Row};
use urlencoding::encode;
use chrono::{NaiveDate, NaiveDateTime, NaiveTime, DateTime, Utc};
use crate::models::{ConnectionParams, TableInfo, TableColumn, QueryResult, Pagination};

pub async fn get_tables(params: &ConnectionParams) -> Result<Vec<TableInfo>, String> {
    let user = encode(params.username.as_deref().unwrap_or_default());
    let pass = encode(params.password.as_deref().unwrap_or_default());
    let url = format!("postgres://{}:{}@{}:{}/{}", 
        user, pass,
        params.host.as_deref().unwrap_or("localhost"), params.port.unwrap_or(5432), params.database);
    let mut conn = sqlx::postgres::PgConnection::connect(&url).await.map_err(|e| e.to_string())?;
    let rows = sqlx::query("SELECT table_name as name FROM information_schema.tables WHERE table_schema = 'public'")
        .fetch_all(&mut conn).await.map_err(|e| e.to_string())?;
    Ok(rows.iter().map(|r| TableInfo { name: r.try_get("name").unwrap_or_default() }).collect())
}

pub async fn get_columns(params: &ConnectionParams, table_name: &str) -> Result<Vec<TableColumn>, String> {
    let user = encode(params.username.as_deref().unwrap_or_default());
    let pass = encode(params.password.as_deref().unwrap_or_default());
    let url = format!("postgres://{}:{}@{}:{}/{}", 
        user, pass,
        params.host.as_deref().unwrap_or("localhost"), params.port.unwrap_or(5432), params.database);
    let mut conn = sqlx::postgres::PgConnection::connect(&url).await.map_err(|e| e.to_string())?;
    
    // Postgres auto increment is usually sequences (nextval) or GENERATED BY DEFAULT/ALWAYS AS IDENTITY
    let query = r#"
        SELECT 
            c.column_name, 
            c.data_type, 
            c.is_nullable,
            c.column_default,
            c.is_identity,
            (SELECT COUNT(*) FROM information_schema.table_constraints tc 
             JOIN information_schema.key_column_usage kcu ON tc.constraint_name = kcu.constraint_name
             WHERE tc.constraint_type = 'PRIMARY KEY' 
             AND kcu.table_name = c.table_name 
             AND kcu.column_name = c.column_name) > 0 as is_pk
        FROM information_schema.columns c
        WHERE c.table_schema = 'public' AND c.table_name = $1
        ORDER BY c.ordinal_position
    "#;

    let rows = sqlx::query(query)
        .bind(table_name)
        .fetch_all(&mut conn).await.map_err(|e| e.to_string())?;

    Ok(rows.iter().map(|r| {
        let null_str: String = r.try_get("is_nullable").unwrap_or_default();
        let is_pk: i64 = r.try_get("is_pk").unwrap_or(0);
        let default_val: String = r.try_get("column_default").unwrap_or_default();
        let is_identity: String = r.try_get("is_identity").unwrap_or_default(); // YES/NO
        
        let is_auto = is_identity == "YES" || default_val.contains("nextval");

        TableColumn {
            name: r.try_get("column_name").unwrap_or_default(),
            data_type: r.try_get("data_type").unwrap_or_default(),
            is_pk: is_pk > 0,
            is_nullable: null_str == "YES",
            is_auto_increment: is_auto,
        }
    }).collect())
}

pub async fn delete_record(params: &ConnectionParams, table: &str, pk_col: &str, pk_val: serde_json::Value) -> Result<u64, String> {
    let user = encode(params.username.as_deref().unwrap_or_default());
    let pass = encode(params.password.as_deref().unwrap_or_default());
    let url = format!("postgres://{}:{}@{}:{}/{}", 
        user, pass,
        params.host.as_deref().unwrap_or("localhost"), params.port.unwrap_or(5432), params.database);
    let mut conn = sqlx::postgres::PgConnection::connect(&url).await.map_err(|e| e.to_string())?;
    
    let query = format!("DELETE FROM \"{}\" WHERE \"{}\" = $1", table, pk_col);
    
    let result = match pk_val {
        serde_json::Value::Number(n) => {
            if n.is_i64() { sqlx::query(&query).bind(n.as_i64()).execute(&mut conn).await }
            else { sqlx::query(&query).bind(n.as_f64()).execute(&mut conn).await }
        },
        serde_json::Value::String(s) => sqlx::query(&query).bind(s).execute(&mut conn).await,
        _ => return Err("Unsupported PK type".into()),
    };
    
    result.map(|r| r.rows_affected()).map_err(|e| e.to_string())
}

pub async fn update_record(params: &ConnectionParams, table: &str, pk_col: &str, pk_val: serde_json::Value, col_name: &str, new_val: serde_json::Value) -> Result<u64, String> {
    let user = encode(params.username.as_deref().unwrap_or_default());
    let pass = encode(params.password.as_deref().unwrap_or_default());
    let url = format!("postgres://{}:{}@{}:{}/{}", 
        user, pass,
        params.host.as_deref().unwrap_or("localhost"), params.port.unwrap_or(5432), params.database);
    let mut conn = sqlx::postgres::PgConnection::connect(&url).await.map_err(|e| e.to_string())?;
    
    let mut qb = sqlx::QueryBuilder::new(format!("UPDATE \"{}\" SET \"{}\" = ", table, col_name));
    
    match new_val {
        serde_json::Value::Number(n) => { if n.is_i64() { qb.push_bind(n.as_i64()); } else { qb.push_bind(n.as_f64()); } },
        serde_json::Value::String(s) => { qb.push_bind(s); },
        serde_json::Value::Bool(b) => { qb.push_bind(b); },
        serde_json::Value::Null => { qb.push("NULL"); },
        _ => return Err("Unsupported Value type".into()),
    }
    
    qb.push(format!(" WHERE \"{}\" = ", pk_col));
    
    match pk_val {
        serde_json::Value::Number(n) => { if n.is_i64() { qb.push_bind(n.as_i64()); } else { qb.push_bind(n.as_f64()); } },
        serde_json::Value::String(s) => { qb.push_bind(s); },
        _ => return Err("Unsupported PK type".into()),
    }
    
    let query = qb.build();
    let result = query.execute(&mut conn).await.map_err(|e| e.to_string())?;
    Ok(result.rows_affected())
}

pub async fn insert_record(params: &ConnectionParams, table: &str, data: std::collections::HashMap<String, serde_json::Value>) -> Result<u64, String> {
    let user = encode(params.username.as_deref().unwrap_or_default());
    let pass = encode(params.password.as_deref().unwrap_or_default());
    let url = format!("postgres://{}:{}@{}:{}/{}", 
        user, pass,
        params.host.as_deref().unwrap_or("localhost"), params.port.unwrap_or(5432), params.database);
    let mut conn = sqlx::postgres::PgConnection::connect(&url).await.map_err(|e| e.to_string())?;
    
    let mut cols = Vec::new();
    let mut vals = Vec::new();
    
    for (k, v) in data {
        cols.push(format!("\"{}\"", k));
        vals.push(v);
    }
    
    if cols.is_empty() { return Err("No data to insert".into()); }
    
    let mut qb = sqlx::QueryBuilder::new(format!("INSERT INTO \"{}\" ({}) VALUES (", table, cols.join(", ")));
    
    let mut separated = qb.separated(", ");
    for val in vals {
        match val {
            serde_json::Value::Number(n) => { if n.is_i64() { separated.push_bind(n.as_i64()); } else { separated.push_bind(n.as_f64()); } },
            serde_json::Value::String(s) => { separated.push_bind(s); },
            serde_json::Value::Bool(b) => { separated.push_bind(b); },
            serde_json::Value::Null => { separated.push("NULL"); },
            _ => return Err("Unsupported value type".into()),
        }
    }
    separated.push_unseparated(")");
    
    let query = qb.build();
    let result = query.execute(&mut conn).await.map_err(|e| e.to_string())?;
    Ok(result.rows_affected())
}

pub async fn execute_query(params: &ConnectionParams, query: &str, limit: Option<u32>, page: u32) -> Result<QueryResult, String> {
    let user = encode(params.username.as_deref().unwrap_or_default());
    let pass = encode(params.password.as_deref().unwrap_or_default());
    let url = format!("postgres://{}:{}@{}:{}/{}", 
        user, pass,
        params.host.as_deref().unwrap_or("localhost"), params.port.unwrap_or(5432), params.database);
    
    let mut conn = sqlx::postgres::PgConnection::connect(&url).await.map_err(|e| e.to_string())?;
    
    let is_select = query.trim_start().to_uppercase().starts_with("SELECT");
    let mut pagination: Option<Pagination> = None;
    let final_query: String;
    let mut manual_limit = limit;

    if is_select && limit.is_some() {
        let l = limit.unwrap();
        let offset = (page - 1) * l;
        
        let count_q = format!("SELECT COUNT(*) FROM ({}) as count_wrapper", query);
        let count_res = sqlx::query(&count_q).fetch_one(&mut conn).await;
        
        let total_rows: u64 = if let Ok(row) = count_res {
            row.try_get::<i64, _>(0).unwrap_or(0) as u64
        } else {
            0
        };

        pagination = Some(Pagination {
            page,
            page_size: l,
            total_rows,
        });

        final_query = format!("SELECT * FROM ({}) as data_wrapper LIMIT {} OFFSET {}", query, l, offset);
        manual_limit = None;
    } else {
        final_query = query.to_string();
    }
    
    // Streaming
    let mut rows_stream = sqlx::query(&final_query).fetch(&mut conn);

    let mut columns: Vec<String> = Vec::new();
    let mut json_rows = Vec::new();
    let mut truncated = false;
    
    use futures::stream::StreamExt;

    while let Some(result) = rows_stream.next().await {
        match result {
            Ok(row) => {
                if columns.is_empty() {
                    columns = row.columns().iter().map(|c| c.name().to_string()).collect();
                }

                if let Some(l) = manual_limit {
                    if json_rows.len() >= l as usize {
                        truncated = true;
                        break;
                    }
                }

                let mut json_row = Vec::new();
                for (i, _) in row.columns().iter().enumerate() {
                    let val = if let Ok(v) = row.try_get::<i64, _>(i) { serde_json::Value::from(v) }
                    else if let Ok(v) = row.try_get::<i32, _>(i) { serde_json::Value::from(v) }
                    else if let Ok(v) = row.try_get::<i16, _>(i) { serde_json::Value::from(v) }
                    else if let Ok(v) = row.try_get::<i8, _>(i) { serde_json::Value::from(v) }
                    else if let Ok(v) = row.try_get::<f64, _>(i) { serde_json::Number::from_f64(v).map(serde_json::Value::Number).unwrap_or(serde_json::Value::Null) }
                    else if let Ok(v) = row.try_get::<f32, _>(i) { serde_json::Number::from_f64(v as f64).map(serde_json::Value::Number).unwrap_or(serde_json::Value::Null) }
                    else if let Ok(v) = row.try_get::<String, _>(i) { serde_json::Value::from(v) }
                    else if let Ok(v) = row.try_get::<bool, _>(i) { serde_json::Value::from(v) }
                    // Specific Postgres Types
                    else if let Ok(v) = row.try_get::<DateTime<Utc>, _>(i) { serde_json::Value::String(v.to_string()) }
                    else if let Ok(v) = row.try_get::<NaiveDateTime, _>(i) { serde_json::Value::String(v.to_string()) }
                    else if let Ok(v) = row.try_get::<NaiveDate, _>(i) { serde_json::Value::String(v.to_string()) }
                    else if let Ok(v) = row.try_get::<NaiveTime, _>(i) { serde_json::Value::String(v.to_string()) }
                    else { serde_json::Value::Null };
                    json_row.push(val);
                }
                json_rows.push(json_row);
            }
            Err(e) => return Err(e.to_string()),
        }
    }
    
    Ok(QueryResult { columns, rows: json_rows, affected_rows: 0, truncated, pagination })
}
